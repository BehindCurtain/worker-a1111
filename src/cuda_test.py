#!/usr/bin/env python3
"""
CUDA Compatibility Test for RTX 5090
Tests CUDA availability, compute capability, and PyTorch compatibility
"""

import sys
import torch

def test_cuda_compatibility():
    """Test CUDA compatibility for RTX 5090 (sm_120)"""
    print("=" * 60)
    print("CUDA COMPATIBILITY TEST FOR RTX 5090")
    print("=" * 60)
    
    # Test 1: PyTorch version
    print(f"‚úì PyTorch version: {torch.__version__}")
    
    # Test 2: CUDA availability
    cuda_available = torch.cuda.is_available()
    print(f"{'‚úì' if cuda_available else '‚ùå'} CUDA available: {cuda_available}")
    
    if not cuda_available:
        print("‚ùå CUDA not available. Cannot proceed with GPU tests.")
        return False
    
    # Test 3: CUDA version
    cuda_version = torch.version.cuda
    print(f"‚úì CUDA version: {cuda_version}")
    
    # Test 4: GPU count and details
    gpu_count = torch.cuda.device_count()
    print(f"‚úì GPU count: {gpu_count}")
    
    if gpu_count == 0:
        print("‚ùå No GPUs detected.")
        return False
    
    # Test 5: GPU details and compute capability
    for i in range(gpu_count):
        gpu_name = torch.cuda.get_device_name(i)
        gpu_props = torch.cuda.get_device_properties(i)
        compute_capability = f"{gpu_props.major}.{gpu_props.minor}"
        
        print(f"‚úì GPU {i}: {gpu_name}")
        print(f"  - Compute Capability: sm_{gpu_props.major}{gpu_props.minor}")
        print(f"  - Memory: {gpu_props.total_memory / 1024**3:.1f} GB")
        print(f"  - Multiprocessors: {gpu_props.multi_processor_count}")
        
        # Check if RTX 5090 (sm_120) is supported
        if gpu_props.major == 12 and gpu_props.minor == 0:
            print(f"  ‚úì RTX 5090 (sm_120) detected and supported!")
        elif gpu_props.major >= 12:
            print(f"  ‚úì Advanced GPU architecture (sm_{gpu_props.major}{gpu_props.minor}) supported!")
        elif gpu_props.major >= 8:
            print(f"  ‚úì Modern GPU architecture (sm_{gpu_props.major}{gpu_props.minor}) supported!")
        else:
            print(f"  ‚ö† Older GPU architecture (sm_{gpu_props.major}{gpu_props.minor})")
    
    # Test 6: Simple tensor operation
    try:
        print("\n" + "=" * 40)
        print("TESTING GPU TENSOR OPERATIONS")
        print("=" * 40)
        
        # Create a test tensor on GPU
        device = torch.device('cuda:0')
        test_tensor = torch.randn(1000, 1000, device=device)
        result = torch.matmul(test_tensor, test_tensor.T)
        
        print("‚úì GPU tensor creation: SUCCESS")
        print("‚úì GPU matrix multiplication: SUCCESS")
        print(f"‚úì Result tensor shape: {result.shape}")
        print(f"‚úì Result tensor device: {result.device}")
        
        # Memory info
        allocated = torch.cuda.memory_allocated(0) / 1024**2
        cached = torch.cuda.memory_reserved(0) / 1024**2
        print(f"‚úì GPU memory allocated: {allocated:.1f} MB")
        print(f"‚úì GPU memory cached: {cached:.1f} MB")
        
        # Clean up
        del test_tensor, result
        torch.cuda.empty_cache()
        
        return True
        
    except Exception as e:
        print(f"‚ùå GPU tensor operation failed: {e}")
        return False

def test_xformers_compatibility():
    """Test xformers compatibility"""
    print("\n" + "=" * 40)
    print("TESTING XFORMERS COMPATIBILITY")
    print("=" * 40)
    
    try:
        import xformers
        print(f"‚úì xformers version: {xformers.__version__}")
        
        # Test xformers CUDA compatibility
        import xformers.ops
        print("‚úì xformers.ops imported successfully")
        
        return True
        
    except ImportError as e:
        print(f"‚ùå xformers import failed: {e}")
        return False
    except Exception as e:
        print(f"‚ùå xformers test failed: {e}")
        return False

def main():
    """Main test function"""
    print("Starting CUDA compatibility tests...\n")
    
    # Run CUDA tests
    cuda_ok = test_cuda_compatibility()
    
    # Run xformers tests
    xformers_ok = test_xformers_compatibility()
    
    # Summary
    print("\n" + "=" * 60)
    print("TEST SUMMARY")
    print("=" * 60)
    
    if cuda_ok and xformers_ok:
        print("üéâ ALL TESTS PASSED!")
        print("‚úì RTX 5090 compatibility confirmed")
        print("‚úì Ready for Stable Diffusion inference")
        return 0
    elif cuda_ok:
        print("‚ö† CUDA tests passed, but xformers issues detected")
        print("‚úì Basic GPU operations should work")
        print("‚ö† Performance may be suboptimal without xformers")
        return 1
    else:
        print("‚ùå CUDA COMPATIBILITY ISSUES DETECTED")
        print("‚ùå RTX 5090 may not be properly supported")
        print("‚ùå Check PyTorch and CUDA versions")
        return 2

if __name__ == "__main__":
    sys.exit(main())
